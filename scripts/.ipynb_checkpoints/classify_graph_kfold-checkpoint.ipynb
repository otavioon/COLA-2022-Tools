{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUrHQmiuIxXD"
   },
   "source": [
    "**IMPORTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KRIH85DkIj-5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob as gl\n",
    "import yaml as yl\n",
    "import pickle as pk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from math import sqrt\n",
    "from absl import app, flags, logging\n",
    "from dataclasses import dataclass\n",
    "from google.colab import drive\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "!pip install stellargraph\n",
    "\n",
    "from stellargraph.mapper import PaddedGraphGenerator\n",
    "from stellargraph.layer import DeepGraphCNN\n",
    "from stellargraph.layer import GCNSupervisedGraphClassification\n",
    "from stellargraph import StellarDiGraph\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPool1D, Dropout, Flatten\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.losses import categorical_crossentropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohLsdfY1NmUn"
   },
   "source": [
    "**FLAGS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dt1I2b_xMnbH"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Flags:\n",
    "    \"\"\"Flags\"\"\"\n",
    "    dataset: str\n",
    "    representation: str\n",
    "    train_dataset_directory: str\n",
    "    train_p: int\n",
    "    classes: int\n",
    "    results_directory: str\n",
    "    model: str\n",
    "    patience: int\n",
    "    epochs: int\n",
    "    rounds: int\n",
    "    verbose: bool\n",
    "    print_model: bool\n",
    "    print_cm: bool\n",
    "    print_cr: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cskvWL0_I3DA"
   },
   "source": [
    "**FUNCTIONS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sSyQ8hfiJAbT"
   },
   "outputs": [],
   "source": [
    "def build_model_gcn(X, classes):\n",
    "    generator = PaddedGraphGenerator(graphs=X)\n",
    "\n",
    "    gc_model = GCNSupervisedGraphClassification(\n",
    "        layer_sizes=[64, 64],\n",
    "        activations=[\"relu\", \"relu\"],\n",
    "        generator=generator,\n",
    "        dropout=0.5,\n",
    "    )\n",
    "    x_inp, x_out = gc_model.in_out_tensors()\n",
    "    predictions = Dense(units=32, activation=\"relu\")(x_out)\n",
    "    predictions = Dense(units=16, activation=\"relu\")(predictions)\n",
    "    predictions = Dense(units=classes, activation=\"softmax\")(predictions)\n",
    "    \n",
    "    model = Model(inputs=x_inp, outputs=predictions)\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                  loss=categorical_crossentropy,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sXfjaWreJhCp"
   },
   "outputs": [],
   "source": [
    "def build_model_dgcnn(X, classes):\n",
    "    \"\"\"Create the model.\"\"\"\n",
    "    generator = PaddedGraphGenerator(graphs=X)\n",
    "    \n",
    "    k = 35  # the number of rows for the output tensor\n",
    "    layer_sizes = [32, 32, 32, 1]\n",
    "    \n",
    "    dgcnn_model = DeepGraphCNN(\n",
    "        layer_sizes=layer_sizes,\n",
    "        activations=[\"tanh\", \"tanh\", \"tanh\", \"tanh\"],\n",
    "        k=k,\n",
    "        bias=False,\n",
    "        generator=generator,  \n",
    "    )\n",
    "    x_inp, x_out = dgcnn_model.in_out_tensors()\n",
    "    \n",
    "    x_out = Conv1D(filters=16,\n",
    "                   kernel_size=sum(layer_sizes),\n",
    "                   strides=sum(layer_sizes),\n",
    "                   activation=\"relu\")(x_out)\n",
    "    x_out = MaxPool1D(pool_size=2,\n",
    "                      strides=2)(x_out)\n",
    "    x_out = Conv1D(filters=32,\n",
    "                   kernel_size=5,\n",
    "                   strides=1,\n",
    "                   activation=\"relu\")(x_out)\n",
    "    x_out = Flatten()(x_out)\n",
    "    x_out = Dense(units=128,\n",
    "                  activation=\"relu\")(x_out)\n",
    "    x_out = Dropout(rate=0.5)(x_out)\n",
    "    outputs = Dense(units=classes,\n",
    "                    activation=\"softmax\")(x_out)\n",
    "    \n",
    "    model = Model(inputs=x_inp, outputs=outputs)\n",
    "\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "                  loss=categorical_crossentropy,\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u2en2q22Jl53"
   },
   "outputs": [],
   "source": [
    "def load_dataset(dataset_directory, classes, percentage):\n",
    "    X = []\n",
    "    y = []\n",
    "    y_idx = []\n",
    "    for label in range(1, classes+1):\n",
    "        ddir = os.path.join(dataset_directory, str(label))\n",
    "        samples = gl.glob('{}/*.pk'.format(ddir))\n",
    "        random.shuffle(samples)\n",
    "\n",
    "        total = len(samples)*percentage/100\n",
    "        \n",
    "        counter = 0\n",
    "        for sample in samples:\n",
    "            try:\n",
    "                with open(sample, 'rb') as fin:\n",
    "                    x_val = pk.load(fin)\n",
    "\n",
    "                y_val = label - 1\n",
    "                y.append(y_val)\n",
    "                y_idx.append(len(X))\n",
    "                X.append(x_val)\n",
    "            except:\n",
    "                print('Erro: ', sample)\n",
    "                continue\n",
    "\n",
    "            if counter == total:\n",
    "                break\n",
    "\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "27Z9e0elJ0qM"
   },
   "outputs": [],
   "source": [
    "def execute(FLAGS):\n",
    "    \"\"\"Execute.\"\"\"\n",
    "\n",
    "    # Breakdown the runtime\n",
    "    flags_times = {}\n",
    "\n",
    "    #\n",
    "    # Initialize the execution\n",
    "    #\n",
    "  \n",
    "    #\n",
    "    # Load the dataset\n",
    "    #\n",
    "    print('\\nLoading the dataset ...')\n",
    "    start = time.time()\n",
    "\n",
    "    X, y = load_dataset(FLAGS.train_dataset_directory, FLAGS.classes, FLAGS.train_p)\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    # Store load time\n",
    "    flags_times['loading'] = end - start\n",
    "        \n",
    "    #\n",
    "    # Build the model\n",
    "    #\n",
    "    print('\\nBuilding the dataset ...')\n",
    "\n",
    "    if FLAGS.model == 'gcn':\n",
    "        model = build_model_gcn(X, FLAGS.classes)\n",
    "    elif FLAGS.model == 'dgcnn':\n",
    "        model = build_model_dgcnn(X, FLAGS.classes)\n",
    "    else:\n",
    "        logging.error('Model error.')\n",
    "        sys.exit(1)\n",
    "\n",
    "    if FLAGS.print_model:\n",
    "        print()\n",
    "        model.summary()\n",
    "\n",
    "    #\n",
    "    # Create the output directory\n",
    "    #\n",
    "    os.makedirs(FLAGS.results_directory, exist_ok=True)\n",
    "\n",
    "    #\n",
    "    # Trainning and Test\n",
    "    #\n",
    "\n",
    "    es_callback = EarlyStopping(monitor=\"accuracy\",\n",
    "                                patience=FLAGS.patience,\n",
    "                                restore_best_weights=True)\n",
    "\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=FLAGS.n_splits, shuffle=True, random_state=42)\n",
    "    split = kf.split(X, y)\n",
    "    for i, (train_idx, test_idx) in enumerate(split):\n",
    "        print('\\n====>>> ROUND: {}'.format(i))\n",
    "\n",
    "        #\n",
    "        # Prepare de data\n",
    "        #\n",
    "\n",
    "        gen = PaddedGraphGenerator(graphs=X)\n",
    "        \n",
    "        X_train = gen.flow(list(train_idx),\n",
    "                             targets=pd.get_dummies(y[train_idx]),\n",
    "                             batch_size=50,\n",
    "                             symmetric_normalization=False)\n",
    "        X_test = gen.flow(list(test_idx),\n",
    "                            targets=pd.get_dummies(y[test_idx]),\n",
    "                            batch_size=1,\n",
    "                            symmetric_normalization=False) \n",
    "\n",
    "        #\n",
    "        # Training\n",
    "        #\n",
    "        print('\\nTraining ...')\n",
    "        start = time.time()\n",
    "\n",
    "        history = model.fit(X_train,\n",
    "                            epochs=FLAGS.epochs,\n",
    "                            verbose=1 if FLAGS.verbose else 0,\n",
    "                            shuffle=True,\n",
    "                            callbacks=[es_callback])\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        # Store the training time\n",
    "        flags_times['training_{}'.format(i)] = end - start\n",
    "\n",
    "        if not FLAGS.verbose:\n",
    "            hist = pd.DataFrame(history.history)\n",
    "            print(hist.tail())\n",
    "\n",
    "        #\n",
    "        # Predicting\n",
    "        #\n",
    "        print('\\nPredicting ...')\n",
    "        start = time.time()\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred = y_pred.argmax(axis=-1)\n",
    "        end = time.time()\n",
    "\n",
    "        # Store the predicting time\n",
    "        flags_times['predicting_{}'.format(i)] = end - start\n",
    "\n",
    "        #\n",
    "        # Statistic\n",
    "        #\n",
    "        print('\\nCalculating statistics ...')\n",
    "        acc = accuracy_score(y[test_idx], y_pred)\n",
    "        cm = confusion_matrix(y[test_idx], y_pred)\n",
    "        cr = classification_report(y[test_idx], y_pred)\n",
    "       \n",
    "        print('\\nAccuracy:', acc)\n",
    "\n",
    "        if FLAGS.print_cm:\n",
    "            print('\\nConfusion matrix')\n",
    "            print(cm)\n",
    "\n",
    "        if FLAGS.print_cr:\n",
    "            print('\\nClassification report')\n",
    "            print(cr)\n",
    "\n",
    "        #\n",
    "        # Finalize the execution\n",
    "        #\n",
    "        # Create the output directory\n",
    "        print('\\nStoring the results ...')\n",
    "\n",
    "        # Store the history\n",
    "        np.savez_compressed('{}/history_{}'.format(FLAGS.results_directory, i), values=history)\n",
    "\n",
    "        # Store the statistics\n",
    "        np.savez_compressed('{}/statistics_{}'.format(FLAGS.results_directory, i), cm=cm, cr=cr, acc=acc)\n",
    "\n",
    "        # Store the prediction\n",
    "        np.savez_compressed('{}/y_pred_{}'.format(FLAGS.results_directory, i), values=y_pred)\n",
    "\n",
    "        # Store y_test\n",
    "        np.savez_compressed('{}/y_test_{}'.format(FLAGS.results_directory, i), values=y[test_idx])\n",
    "\n",
    "        # Store the elapsed time\n",
    "        fout = open('{}/elapsed_time_{}.yaml'.format(FLAGS.results_directory, i), 'w')\n",
    "        yl.dump(flags_times, fout)\n",
    "        fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2mU4q-dN2_e"
   },
   "source": [
    "**MAIN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kxliw3yENzBX"
   },
   "outputs": [],
   "source": [
    "# \n",
    "# Flags\n",
    "#\n",
    "flags = Flags(\n",
    "    dataset=\"ojclone32\",\n",
    "    representation=\"histogram\",\n",
    "    train_dataset_directory=\"\",\n",
    "    train_p=100,\n",
    "    classes=32,\n",
    "    results_directory=\"/content/drive/My Drive/CGO2022\",\n",
    "    scaler=False,\n",
    "    model=\"model1\",\n",
    "    patience=50,\n",
    "    epochs=500,\n",
    "    rounds=5,\n",
    "    verbose=False,\n",
    "    print_model=False,\n",
    "    print_cm=False,\n",
    "    print_cr=False\n",
    ")\n",
    "flags.train_dataset_directory = flags.representation\n",
    "flags.results_directory = os.path.join(flags.results_directory, flags.model, flags.representation)\n",
    "\n",
    "#\n",
    "# Get the dataset\n",
    "#\n",
    "wget = 'wget www.csl.uem.br/repository/data/{}/{}.tar.xz'.format(flags.dataset, flags.representation)\n",
    "tar = 'tar xfJ {}.tar.xz'.format(flags.representation)\n",
    "!$wget\n",
    "!$tar\n",
    "\n",
    "#\n",
    "# Open the Drive\n",
    "#\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "#\n",
    "# Execute\n",
    "#\n",
    "execute(flags)\n",
    "\n",
    "#\n",
    "# Flush the Driver\n",
    "#\n",
    "drive.flush_and_unmount()\n",
    "\n",
    "#\n",
    "# Remove the dataset\n",
    "#\n",
    "rm = 'rm -rf {}*'.format(flags.dataset_directory)\n",
    "!$rm"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNVvrJFLsO8eA6w1uJCdq+S",
   "collapsed_sections": [],
   "name": "classify_graph_kfold.ipynb",
   "provenance": [
    {
     "file_id": "1nO1cVA1bvmTAIQgnQ6ZPwPF-6JsOgjlw",
     "timestamp": 1653145800983
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
